{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning<br>\n",
    "<b>Splitting the data in train and test sets\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640, 945, 892, 946, 221, 759, 779, 357, 207, 190, 637, 419, 981, 216, 159, 474, 404, 40, 877, 384, 586, 957, 228, 615, 483, 269, 675, 774, 903, 143, 802, 960, 218, 813, 45, 61, 998, 874, 189, 630, 291, 336, 455, 891, 882, 795, 465, 796, 949, 972, 375, 13, 830, 374, 318, 4, 270, 310, 717, 411, 547, 977, 254, 607, 140, 91, 36, 397, 191, 668, 203, 729, 861, 416, 526, 758, 52, 390, 855, 731, 330, 762, 78, 309, 911, 714, 647, 353, 534, 94, 723, 700, 905, 785, 220, 211, 2, 772, 584, 391, 333, 596, 821, 575, 359, 617, 145, 458, 743, 887, 751, 987, 367, 783, 702, 573, 674, 663, 79, 18, 470, 307, 301, 518, 930, 964, 97, 978, 163, 862, 757, 664, 293, 468, 60, 611, 196, 517, 692, 181, 195, 351, 493, 406, 66, 95, 520, 12, 5, 447, 297, 996, 210, 423, 883, 955, 730, 935, 296, 906, 806, 865, 116, 224, 848, 975, 688, 536, 219, 132, 997, 315, 713, 412, 991, 256, 974, 950, 624, 893, 46, 413, 869, 529, 567, 127, 739, 819, 471, 588, 689, 39, 850, 928, 76, 646, 437, 687, 452, 639, 500, 886, 616, 504, 450, 601, 8, 328, 108, 208, 907, 564, 466, 495, 347, 701, 525, 654, 650, 188, 790, 409, 499, 859, 908, 440, 801, 597, 915, 410, 463, 562, 621, 576, 361, 672, 155, 929, 192, 970, 138, 106, 999, 681, 454, 565, 666, 322, 44, 460, 255, 89, 408, 980, 438, 752, 400, 234, 519, 62, 895, 71, 280, 360, 555, 516, 844, 524, 429, 398, 718, 96, 662, 514, 231, 469, 123, 258, 317, 124, 476, 430, 577, 396, 178, 402, 327, 286, 728, 725, 312, 113, 863, 10, 156, 262, 70, 126, 366, 277, 74, 274, 214, 230, 172, 121, 936, 84, 473, 558, 501, 482, 798, 506, 144, 627, 200, 435, 787, 420, 434, 26, 508, 909, 365, 738, 775, 428, 414, 920, 633, 554, 141, 794, 881, 709, 632, 604, 247, 323, 23, 652, 549, 542, 571, 368, 59, 199, 345, 442, 83, 488, 166, 854, 948, 578, 227, 128, 510, 446, 919, 266, 580, 610, 609, 240, 239, 405, 550, 206, 749, 926, 81, 90, 954, 742, 812, 389, 982, 19, 600, 956, 21, 721, 803, 677, 229, 449, 857, 377, 834, 252, 585, 963, 832, 235, 436, 917, 17, 387, 540, 839, 497, 838, 826, 673, 938, 595, 380, 193, 183, 142, 810, 568, 985, 685, 811, 537, 744, 16, 703, 87, 682, 645, 250, 665, 314, 715, 370, 747, 180, 625, 472, 348, 835, 968, 789, 769, 364, 538, 492, 485, 215, 680, 201, 259, 85, 371, 888, 369, 570, 337, 684, 136, 122, 432, 618, 349, 441, 572, 93, 263, 706, 426, 505, 461, 613, 582, 77, 552, 344, 527, 598, 237, 727, 173, 690, 424, 487, 829, 741, 209, 342, 961, 104, 295, 236, 433, 249, 153, 133, 776, 186, 439, 923, 444, 933, 766, 653, 6, 522, 63, 110, 157, 736, 481, 288, 535, 659, 661, 38, 988, 740, 37, 628, 820, 858, 927, 305, 904, 507, 817, 417, 871, 352, 708, 531, 65, 603, 267, 34, 694, 889, 338, 68, 246, 379, 704, 952, 154, 543, 937, 939, 480, 100, 222, 399, 171, 922, 115, 809, 827, 118, 148, 979, 167, 491, 152, 707, 158, 660, 880, 792, 697, 807, 350, 273, 253, 553, 612, 767, 656, 951, 539, 98, 683, 47, 388, 780, 788, 72, 992, 934, 386, 884, 511, 294, 278, 69, 849, 545, 107, 53, 782, 102, 130, 546, 755, 605, 932, 899, 401, 244, 129, 716, 966, 643, 306, 376, 248, 205, 272, 515, 925, 9, 852, 745, 381, 117, 135, 33, 724, 699, 638, 325, 644, 149, 101, 80, 265, 591, 281, 631, 995, 329, 670, 232, 73, 276, 112, 289, 298, 58, 756, 226, 816, 49, 486, 619, 900, 840, 479, 394, 722, 304, 726, 557, 343, 655, 456, 823, 25, 710, 581, 27, 51, 898, 15, 765, 147, 464, 560, 678, 475, 373, 711, 969, 990, 502, 114, 719, 763, 753, 111, 657, 989, 993, 658, 623, 54, 942, 825, 457, 868, 608, 754, 339, 303, 761, 602, 676, 735, 750, 233, 31, 378, 622, 746, 335, 477, 284, 845, 773, 875, 976, 187, 422, 326, 75, 407, 533, 805, 781, 569, 916, 636, 32, 268, 494, 313, 947, 421, 119, 279, 509, 815, 204, 764, 983, 693, 355, 867, 82, 851, 563, 589, 914, 853, 921, 818]\n",
      "-------------------------------------------------------\n",
      "[346, 959, 866, 175, 679, 462, 695, 897, 902, 103, 870, 319, 797, 241, 712, 431, 92, 614, 748, 151, 125, 649, 967, 894, 620, 760, 913, 846, 720, 176, 503, 67, 340, 962, 513, 242, 445, 548, 635, 941, 824, 994, 770, 331, 918, 931, 626, 150, 225, 243, 831, 290, 587, 648, 320, 358, 971, 302, 843, 217, 629, 847, 165, 489, 453, 7, 808, 160, 804, 822, 292, 179, 771, 162, 161, 257, 667, 137, 733, 484, 29, 202, 641, 532, 43, 777, 523, 299, 24, 669, 876, 496, 691, 197, 512, 198, 791, 890, 885, 261, 372, 316, 799, 551, 185, 382, 28, 984, 734, 425, 164, 943, 356, 131, 177, 634, 324, 873, 238, 544, 30, 671, 395, 574, 864, 212, 264, 879, 732, 182, 55, 321, 778, 737, 686, 528, 134, 50, 415, 800, 924, 332, 11, 910, 20, 953, 418, 393, 169, 901, 593, 0, 592, 556, 443, 341, 965, 784, 530, 940, 223, 42, 427, 383, 48, 403, 521, 498, 768, 308, 213, 146, 35, 57, 696, 599, 912, 86, 174, 56, 88, 842, 251, 561, 944, 698, 168, 385, 139, 793, 448, 467, 459, 642, 651, 836, 541, 99, 490, 559, 451, 271, 41, 260, 275, 170, 606, 184, 958, 300, 896, 872, 245, 392, 590, 973, 837, 283, 579, 478, 833, 287, 828, 841, 856, 594, 22, 814, 120, 14, 705, 860, 354, 285, 194, 986, 282, 3, 786, 363, 878, 334, 1, 311, 109, 64, 105, 362, 583, 566]\n",
      "-------------------------------------------------------\n",
      "Lengths of the sets formed:\n",
      "Train Set: 750\n",
      "Test Set: 250\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from typing import TypeVar, List,Tuple\n",
    "x = TypeVar('x')\n",
    "def split_data(data:List[x],prob:float) -> Tuple[List[x],List[x]]:\n",
    "    data = data[:]\n",
    "    random.shuffle(data)\n",
    "    cut = int(len(data)*prob)\n",
    "    return data[:cut],data[cut:]\n",
    "data = [n for n in range(1000)]\n",
    "train,test  = split_data(data,0.75) #75% is train data\n",
    "print(train)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(test)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Lengths of the sets formed:\")\n",
    "print(\"Train Set:\",len(train))\n",
    "print(\"Test Set:\",len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Splitting the dataset like before but this time considering the variables too.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenghts of the splits:\n",
      "x_train Lenght: 750\n",
      "x_test Lenght: 250\n",
      "y_train Lenght: 750\n",
      "y_test Lenght: 250\n"
     ]
    }
   ],
   "source": [
    "Y = TypeVar('Y') # generic type to represent output variables\n",
    "def train_test_split(xs: List[x],\n",
    "                        ys: List[Y],\n",
    "                        test_pct: float) -> Tuple[List[x], List[x], List[Y],\n",
    "                        List[Y]]:\n",
    "    \n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "    \n",
    "    return ([xs[i] for i in train_idxs], \n",
    "            [xs[i] for i in test_idxs], \n",
    "            [ys[i] for i in train_idxs],\n",
    "            [ys[i] for i in test_idxs]) \n",
    "xs = [x for x in range(1000)] \n",
    "ys = [2 * x for x in xs] \n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)\n",
    "print(\"Lenghts of the splits:\")\n",
    "print(\"x_train Lenght:\",len(x_train))\n",
    "print(\"x_test Lenght:\",len(x_test))\n",
    "print(\"y_train Lenght:\",len(y_train))\n",
    "print(\"y_test Lenght:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "<ul>\n",
    "    <li><b>Accuracy</b></li>\n",
    "    <li><b>Precision</b></li>\n",
    "    <li><b>Recall</b></li>\n",
    "    <li><b>F1 Score (Harmonic Mean of Precision and Recall)</b></li>\n",
    "    </ul>\n",
    "    \n",
    "#### Error types :\n",
    "<ol>\n",
    "    <li><b>TP</b>:True Positive</li>\n",
    "    <li><b>FP</b>:False Positive</li>\n",
    "    <li><b>TN</b>:True Negative</li>\n",
    "    <li><b>FN</b>:False Negative</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct / total\n",
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fp)\n",
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>High Bias and Low Variance: </b>typically corresponds to <i>underfitting</i>   (prolly the data doesn;t have enough features).<br>\n",
    "<b>Low Bias and High Variance: </b>typically corresponds to <i>overfitting</i>   (porlly the data has too many features).<br>\n",
    "<hr>\n",
    "<ul>\n",
    "    <li>High bias can be removed by adding more features to the dataset, getting more data won't be useful</li>\n",
    "    <li>High variance cab be tackled by removing some features from the dataset or get more data.</li>\n",
    "</ul>\n",
    "<hr>\n",
    "<b>Some Machine Learning models used in further notebooks-</b>\n",
    "<ol>\n",
    "    <li><b>The Naive Bayes classifier</b> suited to\n",
    "yes-or-no features.</li>\n",
    "    <li><b>Regression models</b>\n",
    "require numeric features.</li>\n",
    "    <li><b>Decision trees</b> deal\n",
    "with numeric or categorical data.</li>\n",
    "    </ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
