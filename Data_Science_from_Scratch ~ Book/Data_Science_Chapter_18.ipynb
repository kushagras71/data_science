{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Vector, dot\n",
    "\n",
    "def step_function(x:float) -> float:\n",
    "    return 1.0 if x >= 0 else 0.0\n",
    "\n",
    "def perceptron_output(weights:Vector, bias:float,x:Vector) -> float:\n",
    "    calculations = dot(weights, x) + bias\n",
    "    return step_function(calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AND_Gate\n",
    "and_weights = [2. , 2] \n",
    "and_bias = - 3.\n",
    "assert perceptron_output(and_weights, and_bias, [1, 1] ) == 1 \n",
    "assert perceptron_output(and_weights, and_bias, [0, 1] ) == 0 \n",
    "assert perceptron_output(and_weights, and_bias, [1, 0] ) == 0\n",
    "assert perceptron_output(and_weights, and_bias, [0, 0] ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR_Gate\n",
    "or_weights = [2.,2]\n",
    "or_bias = -1\n",
    "assert perceptron_output(or_weights, or_bias, [1, 1] ) == 1 \n",
    "assert perceptron_output(or_weights, or_bias, [0, 1] ) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [1, 0] ) == 1\n",
    "assert perceptron_output(or_weights, or_bias, [0, 0] ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT_Gate\n",
    "not_weights = [-2.]\n",
    "not_bias = 1.\n",
    "assert perceptron_output(not_weights, not_bias, [0] ) == 1\n",
    "assert perceptron_output(not_weights, not_bias, [1] ) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Building the Feed Forward Neural Networks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(t:float) -> float:  # a smooth acivation function\n",
    "    return 1 / (1+math.exp(-t))\n",
    "\n",
    "def neuron_output(weights:Vector, inputs:Vector) -> float:\n",
    "    return sigmoid(dot(weights,inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def feed_forward(neural_network: List[List[Vector]],\n",
    "                 input_vector: Vector) -> List[Vector]:\n",
    "    \n",
    "    outputs: List[Vector] = []\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]\n",
    "        output = [neuron_output(neuron,input_with_bias)\n",
    "                  for neuron in layer]\n",
    "        outputs.append(output)\n",
    "        input_vector = output\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_network = [\n",
    "    [[20.,20,-30],\n",
    "    [20.,20,-10]],\n",
    "    [[-60.,60,-30]]]\n",
    "\n",
    "assert 0.000 < feed_forward(xor_network,[0,0])[-1][0] < 0.001\n",
    "assert 0.999 < feed_forward(xor_network,[1,0])[-1][0] < 1.000\n",
    "assert 0.999 < feed_forward(xor_network,[0,1])[-1][0] < 1.000\n",
    "assert 0.000 < feed_forward(xor_network,[1,1])[-1][0] < 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqerror_gradient(network:List[List[Vector]],\n",
    "                     input_vector: Vector,\n",
    "                     target_vector: Vector) -> List[List[Vector]]:\n",
    "    hidden_outputs, outputs = feed_forward(network,input_vector)\n",
    "    output_deltas = [output * (1-output) * (output-target)\n",
    "                     for output, target in zip(outputs,target_vector)]\n",
    "    \n",
    "    output_grads = [[output_deltas[i] * hidden_output\n",
    "                     for hidden_output in hidden_outputs + [1]]\n",
    "                    for i,output_neuron in enumerate(network[-1])]\n",
    "    \n",
    "    hidden_deltas = [hidden_output * (1-hidden_output) * \n",
    "                        dot(output_deltas,[n[i] for n in network[-1]])\n",
    "                    for i,hidden_output in enumerate(hidden_outputs)]\n",
    "    \n",
    "    hidden_grads = [[hidden_deltas[i] * input for input in input_vector + [1]]\n",
    "                   for i, hidden_neuron in enumerate(network[0])]\n",
    "    return [hidden_grads,output_grads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing xor gate with Backprop\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "xs = [[0.,0],[0.,1],[1.,0],[1.,1]]\n",
    "ys = [[0.],[1.],[1.],[0.]]\n",
    "\n",
    "#starting with random weights\n",
    "\n",
    "network = [\n",
    "    [[random.random() for _ in range(2+1)],\n",
    "      [random.random() for _ in range(2+1)]],\n",
    "     [[random.random() for _ in range(2+1)]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neural net for xor: 100%|█████████████████████████████████████████████████████| 20000/20000 [00:01<00:00, 12002.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from scratch.gradient_descent import gradient_step\n",
    "import tqdm\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "for epoch in tqdm.trange(20000, desc='neural net for xor'):\n",
    "    for x,y in zip(xs,ys):\n",
    "        gradients = sqerror_gradient(network,x,y)\n",
    "        network = [[gradient_step(neuron,grad,-learning_rate)\n",
    "                    for neuron, grad in zip(layer, layer_grad)]\n",
    "                   for layer,layer_grad in zip(network,gradients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert feed_forward(network,[0,0])[-1][0] < 0.01\n",
    "assert feed_forward(network,[0,1])[-1][0] > 0.99\n",
    "assert feed_forward(network,[1,0])[-1][0] > 0.99\n",
    "assert feed_forward(network,[1,1])[-1][0] < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example - </b><br>\n",
    "Question - <br>\n",
    "Print the numbers 1 to 100, except that if the number is divisible by 3 <br>print \" fizz\" ; if the number is divisible by 5, print \" buzz\" ;<br>\n",
    "and if the number is divisible by 15, print \" fizzbuzz\" .<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizz_buzz_encode(x:int) -> Vector:\n",
    "    if x % 15 == 0:\n",
    "        return [0,0,0,1]\n",
    "    elif x % 5 == 0:\n",
    "        return [0,0,1,0]\n",
    "    elif x % 3 == 0:\n",
    "        return [0,1,0,0]\n",
    "    else:\n",
    "        return [1,0,0,0]\n",
    "\n",
    "assert fizz_buzz_encode(2) == [1,0,0,0]\n",
    "assert fizz_buzz_encode(6) == [0,1,0,0]\n",
    "assert fizz_buzz_encode(10) == [0,0,1,0]\n",
    "assert fizz_buzz_encode(30) == [0,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using  a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numbers to binary representation\n",
    "\n",
    "def binary_encode(x:int) -> Vector:\n",
    "    binary: List[float] = []\n",
    "    for i in range(10):\n",
    "        binary.append(x%2)\n",
    "        x = x//2\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2 4 8 16 32 64 128 256 512\n",
    "assert binary_encode(0) == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert binary_encode(1) == [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert binary_encode(10) == [0, 1, 0, 1, 0, 0, 0, 0, 0, 0] \n",
    "assert binary_encode(101) == [1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "assert binary_encode(999) == [1, 1, 1, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [binary_encode(n) for n in range(101,1024)]\n",
    "ys = [fizz_buzz_encode(n) for n in range(101,1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 25\n",
    "network = [\n",
    "    [[random.random() for _ in range(10+1)] for _ in range(NUM_HIDDEN)],\n",
    "    [[random.random()for _ in range(NUM_HIDDEN + 1)] for i in range(4)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fizz buzz (loss:42.27): 100%|████████████████████████████████████████████████████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from scratch.linear_algebra import squared_distance\n",
    "learning_rate = 1.0\n",
    "\n",
    "with tqdm.trange(500) as t:\n",
    "    for epoch in t:\n",
    "        epoch_loss = 0.0\n",
    "        for x,y in zip(xs,ys):\n",
    "            predicted = feed_forward(network,x)[-1]\n",
    "            epoch_loss += squared_distance(predicted,y)\n",
    "            gradients = sqerror_gradient(network,x,y)\n",
    "            \n",
    "            network = [[gradient_step(neuron,grad,-learning_rate)\n",
    "                        for neuron,grad in zip(layer,layer_grad)]\n",
    "                      for layer, layer_grad in zip(network,gradients)]\n",
    "        t.set_description(f'fizz buzz (loss:{epoch_loss:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the predictions - \n",
    "\n",
    "def argmax(xs:list) -> int:\n",
    "    return max(range(len(xs)),key=lambda i: xs[i])\n",
    "\n",
    "assert argmax([0,-1]) == 0\n",
    "assert argmax([-1,0]) == 1\n",
    "assert argmax([-1,10,5,20,-3]) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "1 / 100\n",
      "2 2 2\n",
      "2 / 100\n",
      "3 fizz fizz\n",
      "3 / 100\n",
      "4 4 4\n",
      "4 / 100\n",
      "5 buzz buzz\n",
      "5 / 100\n",
      "6 fizz fizz\n",
      "6 / 100\n",
      "7 7 7\n",
      "7 / 100\n",
      "8 8 8\n",
      "8 / 100\n",
      "9 fizz fizz\n",
      "9 / 100\n",
      "10 buzz buzz\n",
      "10 / 100\n",
      "11 11 11\n",
      "11 / 100\n",
      "12 fizz fizz\n",
      "12 / 100\n",
      "13 13 13\n",
      "13 / 100\n",
      "14 14 14\n",
      "14 / 100\n",
      "15 fizzbuzz fizzbuzz\n",
      "15 / 100\n",
      "16 16 16\n",
      "16 / 100\n",
      "17 17 17\n",
      "17 / 100\n",
      "18 fizz fizz\n",
      "18 / 100\n",
      "19 19 19\n",
      "19 / 100\n",
      "20 buzz buzz\n",
      "20 / 100\n",
      "21 fizz fizz\n",
      "21 / 100\n",
      "22 22 22\n",
      "22 / 100\n",
      "23 23 23\n",
      "23 / 100\n",
      "24 fizz fizz\n",
      "24 / 100\n",
      "25 buzz buzz\n",
      "25 / 100\n",
      "26 26 26\n",
      "26 / 100\n",
      "27 fizz fizz\n",
      "27 / 100\n",
      "28 28 28\n",
      "28 / 100\n",
      "29 29 29\n",
      "29 / 100\n",
      "30 fizzbuzz fizzbuzz\n",
      "30 / 100\n",
      "31 31 31\n",
      "31 / 100\n",
      "32 32 32\n",
      "32 / 100\n",
      "33 fizz fizz\n",
      "33 / 100\n",
      "34 34 34\n",
      "34 / 100\n",
      "35 buzz buzz\n",
      "35 / 100\n",
      "36 fizz fizz\n",
      "36 / 100\n",
      "37 37 37\n",
      "37 / 100\n",
      "38 38 38\n",
      "38 / 100\n",
      "39 fizz fizz\n",
      "39 / 100\n",
      "40 buzz buzz\n",
      "40 / 100\n",
      "41 41 41\n",
      "41 / 100\n",
      "42 fizz fizz\n",
      "42 / 100\n",
      "43 43 43\n",
      "43 / 100\n",
      "44 44 44\n",
      "44 / 100\n",
      "45 fizzbuzz fizzbuzz\n",
      "45 / 100\n",
      "46 46 46\n",
      "46 / 100\n",
      "47 47 47\n",
      "47 / 100\n",
      "48 fizz fizz\n",
      "48 / 100\n",
      "49 49 49\n",
      "49 / 100\n",
      "50 buzz buzz\n",
      "50 / 100\n",
      "51 fizz fizz\n",
      "51 / 100\n",
      "52 52 52\n",
      "52 / 100\n",
      "53 53 53\n",
      "53 / 100\n",
      "54 fizz fizz\n",
      "54 / 100\n",
      "55 buzz buzz\n",
      "55 / 100\n",
      "56 56 56\n",
      "56 / 100\n",
      "57 fizz fizz\n",
      "57 / 100\n",
      "58 58 58\n",
      "58 / 100\n",
      "59 59 59\n",
      "59 / 100\n",
      "60 fizzbuzz fizzbuzz\n",
      "60 / 100\n",
      "61 61 61\n",
      "61 / 100\n",
      "62 62 62\n",
      "62 / 100\n",
      "63 fizz fizz\n",
      "63 / 100\n",
      "64 64 64\n",
      "64 / 100\n",
      "65 buzz buzz\n",
      "65 / 100\n",
      "66 fizz fizz\n",
      "66 / 100\n",
      "67 67 67\n",
      "67 / 100\n",
      "68 68 68\n",
      "68 / 100\n",
      "69 fizz fizz\n",
      "69 / 100\n",
      "70 buzz buzz\n",
      "70 / 100\n",
      "71 71 71\n",
      "71 / 100\n",
      "72 fizz fizz\n",
      "72 / 100\n",
      "73 73 73\n",
      "73 / 100\n",
      "74 74 74\n",
      "74 / 100\n",
      "75 fizzbuzz fizzbuzz\n",
      "75 / 100\n",
      "76 76 76\n",
      "76 / 100\n",
      "77 buzz 77\n",
      "76 / 100\n",
      "78 fizz fizz\n",
      "77 / 100\n",
      "79 79 79\n",
      "78 / 100\n",
      "80 buzz buzz\n",
      "79 / 100\n",
      "81 fizz fizz\n",
      "80 / 100\n",
      "82 82 82\n",
      "81 / 100\n",
      "83 83 83\n",
      "82 / 100\n",
      "84 fizz fizz\n",
      "83 / 100\n",
      "85 85 buzz\n",
      "83 / 100\n",
      "86 86 86\n",
      "84 / 100\n",
      "87 fizz fizz\n",
      "85 / 100\n",
      "88 88 88\n",
      "86 / 100\n",
      "89 89 89\n",
      "87 / 100\n",
      "90 fizzbuzz fizzbuzz\n",
      "88 / 100\n",
      "91 91 91\n",
      "89 / 100\n",
      "92 buzz 92\n",
      "89 / 100\n",
      "93 buzz fizz\n",
      "89 / 100\n",
      "94 94 94\n",
      "90 / 100\n",
      "95 buzz buzz\n",
      "91 / 100\n",
      "96 fizz fizz\n",
      "92 / 100\n",
      "97 97 97\n",
      "93 / 100\n",
      "98 98 98\n",
      "94 / 100\n",
      "99 fizz fizz\n",
      "95 / 100\n",
      "100 buzz buzz\n",
      "96 / 100\n"
     ]
    }
   ],
   "source": [
    "#finally printing the fizz-buzz\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in range(1,101):\n",
    "    x = binary_encode(n)\n",
    "    predicted = argmax(feed_forward(network,x)[-1])\n",
    "    actual  = argmax(fizz_buzz_encode(n))\n",
    "    labels = [str(n),'fizz','buzz','fizzbuzz']\n",
    "    print(n,labels[predicted],labels[actual])\n",
    "    if predicted == actual:\n",
    "        num_correct += 1\n",
    "    print(num_correct,'/',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
